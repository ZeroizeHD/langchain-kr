{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    \"data/appendix-keywords.txt\", embedding=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG prompt\n",
    "from langchain import hub\n",
    "\n",
    "# Loads the latest version\n",
    "prompt = hub.pull(\"rlm/rag-prompt\", api_url=\"https://api.hub.langchain.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Open Source는 소프트웨어, 하드웨어 또는 다른 유형의 제품 또는 서비스에서 내부적으로 사용하는 소스 코드를 공개하고 여러 사용자가 접근하고 수정할 수 있는 개방형 개발 방식을 의미합니다. 특히 소스 코드가 공개되어 있기 때문에 누구나 해당 소프트웨어를 자유롭게 사용, 복제, 수정, 배포할 수 있으며, 커뮤니티 형태로 개발된 소프트웨어 프로젝트가 주로 Open Source로 알려져 있습니다.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI()\n",
    "\n",
    "retrieval_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "retrieval_chain.invoke(\"Open Source 에 대해서 알려줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "# Step 1: 문서 로드\n",
    "# loader = TextLoader(\"data/appendix-keywords.txt\")\n",
    "# PDF 파일 로드. 파일의 경로 입력\n",
    "loader = PyPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "loader2 = PyPDFLoader(\"data/SPRi AI Brief_5월호_산업동향 최종.pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼성전자에서 자체 개발한 AI의 이름은 '삼성 가우스'입니다.\n",
      "\n",
      "출처: SPRi AI Brief, 2023년 12월호, 페이지 12."
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "# Step 1: 문서 로드\n",
    "# loader = TextLoader(\"data/appendix-keywords.txt\")\n",
    "\n",
    "# Step 1: 문서 로드\n",
    "# loader = TextLoader(\"data/appendix-keywords.txt\")\n",
    "# PDF 파일 로드. 파일의 경로 입력\n",
    "loader = PyPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "loader2 = PyPDFLoader(\"data/SPRi AI Brief_5월호_산업동향 최종.pdf\")\n",
    "\n",
    "# Step 2: 문서 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,  # 500자로 문서를 분할\n",
    "    chunk_overlap=50,  # 50자의 중복을 허용\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "docs1 = loader.load_and_split(text_splitter)\n",
    "docs2 = loader.load_and_split(text_splitter)\n",
    "docs = docs1 + docs2\n",
    "# docs = loader.load_and_split(text_splitter)\n",
    "\n",
    "# Step 3: 벡터 저장소 생성 & 임베딩(문장을 숫자 표현으로 바꾼다!!) -> 저장\n",
    "vectorstore = FAISS.from_documents(docs, OpenAIEmbeddings())\n",
    "\n",
    "# Step 4: 검색기(retriever) -> 나중에 질문(Query) 에 대한 유사도 검색을 하기 위함\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Step 5: 프롬프트 작성, context: 검색기에서 가져온 문장, question: 질문\n",
    "template = \"\"\"당신은 문서에 대한 정보를 바탕으로 답변하는 친절한 Assistant 입니다. 무조건, 주어진 Context 바탕으로 답변해 주세요.\n",
    "답변에 대한 출처도 함께 제공해 주세요.\n",
    "\n",
    "#Context:\n",
    "{context}\n",
    "\n",
    "#Question: \n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "# # Step 5: 프롬프트 작성, context: 검색기에서 가져온 문장, question: 질문\n",
    "# template = \"\"\"Answer the question based only on the following context:\n",
    "# {context}\n",
    "\n",
    "# Question: {question}\n",
    "# \"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Step 6: OpenAI GPT-4 모델을 설정\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o\", streaming=True, callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "# Step 7: 질문에 대한 답변을 찾기 위한 체인 생성\n",
    "retrieval_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Step 8: 질문&답변\n",
    "_ = retrieval_chain.invoke(\"삼성전자에서 자체 개발한 AI 의 이름은 뭐야?\")\n",
    "\n",
    "# # Step 8: 질문&답변\n",
    "# _ = retrieval_chain.invoke(\"Word2Vec 에 대해서 알려줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
